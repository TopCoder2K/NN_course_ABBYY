{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from data_generation import generate_toy_dataset, pad_sequences, \\\n",
    "    one_hot_encode_sequences\n",
    "from utils import batch_generator, display_metrics, compare_sequences, \\\n",
    "    visualize_attention, calculate_loss, calculate_metric, train\n",
    "from models import EncoderDecoder, EncDecAttnDotProduct, EncDecAttnBilinear, EncDecAttnConcat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметр инициализации генератора случайных чисел для возможности воспроизведения результатов экспериментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация данных\n",
    "Для демонстрации работы Механизма Внимания воспользуемся синтетическими данными. В качестве входной последовательности будет выступать последовательность из букв латинского алфавита с повторениями, а на выходе - та же последовательность в исходном порядке.\n",
    "\n",
    "Используемые данные нужны исключительно для демонстрации работы моделей. В реальном приложении данные могли бы представлять:\n",
    "* последовательность пар предложений, где второе предложение является переводом первого на другой естественный язык (задача машинного перевода);\n",
    "* последовательность пар \"запрос-ответ\" (чат-боты);\n",
    "* большой текст и \"выжимка\" из него (краткое изложение содержания) и др."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем датасет со следующими параметрами:\n",
    "* Словарь - буквы латинского алфавита. Будем считать, что токен в нашей последовательности - один символ.\n",
    "* Минимальная длина последовательности - 2, максимальная - 10.\n",
    "* Число записей - 15000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = np.array(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "print(\"Vocabulary:\", vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_MAX_LEN = 10\n",
    "copy_dataset = generate_toy_dataset(vocabulary, seq_min_len=2,\n",
    "                                    seq_max_len=SEQ_MAX_LEN,\n",
    "                                    seq_count=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сформируем последовательности одинаковой длины `sequence_max_size` + 2:\n",
    "* В начале каждой последовательности поставим символ `bos` (begin of sequence).\n",
    "* В конце последовательности поставим символ `eos` (end of sequence). Если итоговая длина полученной последовательности получилась меньше требуемой, добавляем `eos` до тех пор, пока не получим требуемую длину.\n",
    "\n",
    "Возникает закономерный вопрос, зачем мы это делаем.\n",
    "1. Декодеру нужно сообщить о начале последовательности. Свое первое состояние декодер берет из последнего состояния энкодера, а что взять в качестве первого входного токена для декодера? Символ начала последовательности `bos`.\n",
    "2. Работа декодера должна завершатся, когда сгенерирована вся последовательность. Для этого мы будем учить его предсказывать специальный символ конца последовательности `eos`. \n",
    "3. Процедура формирования последовательностей одинаковой длины необходима, так как мы хотим обучать сеть батчами, а не по одному примеру прогонять за раз.\n",
    "\n",
    "Для обучения сети батчами нам также понадобятся бинарные маски для последовательностей. Вектор маски имеет тот же размер, что и последовательность, при этом нули в ней сооветствуют лишним символам `eos`, а единицы всем остальным символам. Данные маски понадобятся при определении лосс-функции и для реализации экодера. Бинарные маски для входной последовательности содержатся в поле `mask_inference_input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = \"*\"\n",
    "EOS = \"#\"\n",
    "copy_dataset = pad_sequences(copy_dataset, SEQ_MAX_LEN, BOS, EOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работать с символами напрямую мы не можем, переводим символы в числа. Закодируем символы следующим образом:\n",
    "* bos закодируем числом 0;\n",
    "* eos закодируем числом 1;\n",
    "* все остальные символы закодируем по порядку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_CODE = 0\n",
    "EOS_CODE = 1\n",
    "sym2num = {sym: i+2 for i, sym in enumerate(vocabulary)}\n",
    "sym2num.update({BOS: BOS_CODE, EOS: EOS_CODE})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вместо последовательности токенов фиксированной длины имеем последовательность фиксированной длины из чисел. Произведем One Hot кодирование этой числовой последовательности.\n",
    "\n",
    "Всего в закодированной исходной числовой последовательности `N=28` различных чисел (2 для специальных символов и 26 для символов алфавита). Для кажого числа `x` в исходной последовательности поставим в соответсвтвие вектор размерности 28 из нулей и одной единицы на позиции = числу `x`.\n",
    "\n",
    "Пусть, например, мы кодируем последовательность `[*, a, #, #]` или `[0, 2, 1, 1]`, причем `N=4`. Тогда число `x=0` будем кодировать вектором `[1, 0, 0, 0]`, `x=1` вектором `[0, 1, 0, 0]`, `x=2` вектором `[0, 0, 1, 0]`.\n",
    "Полученные векторы сложим в одну матрицу и получим \n",
    "`[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0]]` - закодированную последовательность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_dataset = one_hot_encode_sequences(copy_dataset, sym2num)\n",
    "copy_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы не воспользовались методами класса <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html>OneHotEncoder</a> из `sklearn.preprocessing` с целью пошаговой подробной демонстрации происходящего. Разумеется, когда вы будете решать не учебные задачи, вам нужно будет пользоваться уже готовыми реализациями. Также вряд ли вам когда-либо надо будет иметь дело с one-hot векторами напрямую, а не с их sparse-версиями (возможность создания sparse векторов также есть у `OneHotEncoder`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем разбиение датасета на обучающую выборку, валидацию и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(copy_dataset, test_size=0.25,\n",
    "                                         random_state=10)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.25,\n",
    "                                       random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим также, что для обучения рекуррентых сетей батчами в pytorch есть специальные функции:\n",
    "1. <a href=https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html>pad_sequence</a>: позволяет получать последовательности одинаковой длины в батче.\n",
    "2. <a href=https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence>pack_padded_sequence</a>: позволяет не совершать лишних итераций рекуррентной сети.\n",
    "\n",
    "<a href=https://stackoverflow.com/a/55805785/12919840>Тут</a> можно почитать про это."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель Encoder-Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый класс `BaseEncoderDecoder` определен в файле `model.py`.\n",
    "1. Кодирование (`self.encode`) исходной последовательности осуществляется при помощи линейного слоя `self.embedding`. Обратите внимание на параметры этого линейного слоя (какая входная размерность векторов, какая выходная).\n",
    "   * Матрица весов слоя `self.embedding` умножается на закодированную one-hot последовательность, что позволяет перейти от бинарных векторов для токенов к действительным векторам.\n",
    "   * Эта операция может быть весьма затратной в той реализации, которая представлена здесь. Дело в том, что словарь для реальных данных обычно состоит не из 26 токенов (+2 токена bos и eos), а из десятков тысяч токенов. В этом случае каждый one-hot вектор для токена будет содержать десятки тысяч значений, и матрица весов слоя `self.embedding` будет перемножаться с вектором большой размерности, что весьма вычислительно затратно.\n",
    "   * С другой стороны, зачем нам вообще нужны one-hot вектора и матричное умножение? Ведь умножение one-hot вектора на матрицу равносильно просто выбору строки из данной матрицы. Слой <a href=https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html>Embedding</a> из `torch.nn` именно это и делает. При решении не учебной задачи можно воспользоваться <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder>OrdinalEncoder</a> из `sklearn.preprocessing` для кодирования токенов в натуральные числа, а в самой сети добавить слой `Embedding` (см. документацию).\n",
    "2. В коде, где происходит генерация скрытых состояний кодируемой последовательности присутствует такая строчка:\n",
    "```\n",
    "# save new state for not eos tokens, otherwise save prev state\n",
    "state = torch.where(\n",
    "    torch.tile(mask_inference_inputs[:, i, None],\n",
    "               [1, next_state.shape[1]]),\n",
    "    next_state, state\n",
    ")\n",
    "```\n",
    "Зачем нужен этот код? Впишите свой ответ в ячейке ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ:</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Как видно из кода модели, декодирование в режиме обучения (когда `self.training` == True) и режиме инференса (в противном случае) осуществляется при помощи разных методов (`self.decode_training` и `self.decode_eval`). Почему? Впишите свой ответ в ячейке ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Какая используется стратегия декодирования на этапе инференса? Какие еще стратегии декодирования вы знаете?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. На вход энкодеру приходит вектор размерности `embed_size + len(mapping)`. Почему? Какие дополнительные признаки были добавлены к эмбеддинговым признакам в коде?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Без Механизма Внимания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим первую модель, с которой проведем эксперимент. Это обычная модель Encoder-Decoder без использования Механизма Внимания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_model = EncoderDecoder(sym2num, BOS, EOS, embed_size=50,\n",
    "                               enc_hidden_size=70, dec_hidden_size=70)\n",
    "optimizer = torch.optim.Adam(enc_dec_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества модели воспользуемся расстоянием Левенштейна, деленным на максимальную длину из длин истинной или предсказанной последовательности. Чем меньше расстояние между этими последовательностями, тем модель делает более точные предсказания.\n",
    "\n",
    "Всю информацию о процессе обучения смотри в файле `utils.py`, функция `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train(enc_dec_model, train_data, val_data, optimizer, SEQ_MAX_LEN,\n",
    "          batch_size=50, epochs_count=80)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sequences(enc_dec_model, val_data, SEQ_MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашняя работа:</b>\n",
    "1. Проведите несколько экспериментов с данной моделью. Саму модель не надо менять, меняйте параметры оптимизатора, число эпох обучения и размер батча.\n",
    "2. Получите качество лучшей модели на тестовой выборке.\n",
    "3. Сделайте выводы, в которых в том числе отметьте: сколько эпох потребовалось для обучения, какое финальное качество модели вы получили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте добавим Механизм Внимания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## С добавлением Механизма Внимания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашняя работа</b>: реализовать требуемые классы в файле `models.py` и обучить модели.\n",
    "\n",
    "Перед реализацией моделей посмотри код для визуализации весов Внимания: файл `utils.py`, функция  `visualize_attention`.\n",
    "В коде моделей есть `attn_weights` поле, которое вы должны заполнить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скалярное произведение (Dot-Product)\n",
    "Реализуйте Encoder-Decoder сеть с Механизмом Внимания в виде простого скалярного произведения (класс `EncDecAttnDotProduct`).\n",
    "$$logit_i = <enc_{i}, dec>, $$\n",
    "где $i \\in \\overline{0, N_{e}}$, $N_{e}$ - число состояний энкодера.\n",
    "\n",
    "<b>! Обратите внимание</b>, что полученные логиты еще не являются весами Внимания. Для получения весов нужно:\n",
    "1. Наложить бинарную маску: те логиты, которые относятся к дополнительным `eos` токенам приравняйте к $-\\infty$, т.е. к $-10^{9}$.\n",
    "2. Применить Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_dot_product = EncDecAttnDotProduct(\n",
    "    sym2num, BOS, EOS, embed_size=50, enc_hidden_size=70,\n",
    "    dec_hidden_size=70)\n",
    "optimizer = torch.optim.Adam(enc_dec_dot_product.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train(enc_dec_dot_product, train_data, val_data, optimizer, SEQ_MAX_LEN,\n",
    "          batch_size=50, epochs_count=5)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sequences(enc_dec_dot_product, val_data, SEQ_MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_attention(enc_dec_dot_product, val_data, SEQ_MAX_LEN, BOS, EOS,\n",
    "                    batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашняя работа:</b>\n",
    "1. Проведите несколько экспериментов с данной моделью. Саму модель не надо менять, меняйте параметры оптимизатора, число эпох обучения и размер батча.\n",
    "2. Получите качество лучшей модели на тестовой выборке.\n",
    "3. Визуализируйте веса Внимания лучшей модели.\n",
    "4. Сделайте выводы, в которых в том числе отметьте: сколько эпох потребовалось для обучения, какое финальное качество модели вы получили. Лучше ли данная модель с точки зрения определенной метрики на тестовой выборки, чем Encoder-Decoder без внимания? Отличается ли число параметров текущей модели от числа параметров модели без внимания? О чем это говорит?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Билинейное Внимание\n",
    "\n",
    "Реализуйте Encoder-Decoder сеть с Механизмом Внимания в следующем виде (класс `EncDecAttnBilinear`):\n",
    "1. К состоянию энкодера применяется линейное преобразование.\n",
    "2. Затем считается скалярное произведение между обновленным состоянием энкодера и состоянием декодера.\n",
    "\n",
    "$$logit_i = <linear(enc_{i}), dec>, $$\n",
    "где $i \\in \\overline{0, N_{e}}$, $N_{e}$ - число состояний энкодера.\n",
    "\n",
    "<b>! Обратите внимание</b>, что полученные логиты еще не являются весами Внимания. Для получения весов нужно:\n",
    "1. Наложить бинарную маску: те логиты, которые относятся к дополнительным `eos` токенам приравняйте к $-\\infty$, т.е. к $-10^{9}$.\n",
    "2. Применить Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_bilinear = EncDecAttnBilinear(\n",
    "    sym2num, BOS, EOS, embed_size=50, enc_hidden_size=70,\n",
    "    dec_hidden_size=70)\n",
    "optimizer = torch.optim.Adam(enc_dec_bilinear.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train(enc_dec_bilinear, train_data, val_data, optimizer, SEQ_MAX_LEN,\n",
    "          batch_size=50, epochs_count=11)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sequences(enc_dec_bilinear, val_data, SEQ_MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_attention(enc_dec_bilinear, val_data, SEQ_MAX_LEN, BOS, EOS,\n",
    "                    batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашняя работа:</b>\n",
    "1. Проведите несколько экспериментов с данной моделью. Саму модель не надо менять, меняйте параметры оптимизатора, число эпох обучения и размер батча.\n",
    "2. Получите качество лучшей модели на тестовой выборке.\n",
    "3. Визуализируйте веса Внимания лучшей модели.\n",
    "4. Сделайте выводы, в которых в том числе отметьте: сколько эпох потребовалось для обучения, какое финальное качество модели вы получили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Конкатенакция\n",
    "\n",
    "Реализуйте Encoder-Decoder сеть с Механизмом Внимания в следующем виде (класс `EncDecAttnConcat`):\n",
    "1. Состояние энкодера конкатенируется с состоянием декодера.\n",
    "2. Применяется линейный слой (выходная размерность вектора = `dec_hidden_size`).\n",
    "3. Применяется тангенс гиперболический.\n",
    "4. Осуществляется скалярное произведение с обучаемым вектором.\n",
    "\n",
    "$$concat_i = concatenate(enc_{i}, dec)$$\n",
    "$$logit_i = <tanh(linear(concat_i)), vec>$$\n",
    "где $i \\in \\overline{0, N_{e}}$, $N_{e}$ - число состояний энкодера.\n",
    "\n",
    "<b>! Обратите внимание</b>, что полученные логиты еще не являются весами Внимания. Для получения весов нужно:\n",
    "1. Наложить бинарную маску: те логиты, которые относятся к дополнительным `eos` токенам приравняйте к $-\\infty$, т.е. к $-10^{9}$.\n",
    "2. Применить Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_concat = EncDecAttnConcat(\n",
    "    sym2num, BOS, EOS, embed_size=50, enc_hidden_size=70,\n",
    "    dec_hidden_size=70)\n",
    "optimizer = torch.optim.Adam(enc_dec_concat.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train(enc_dec_concat, train_data, val_data, optimizer, SEQ_MAX_LEN,\n",
    "          batch_size=50, epochs_count=15)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sequences(enc_dec_concat, val_data, SEQ_MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_attention(enc_dec_concat, val_data, SEQ_MAX_LEN, BOS, EOS, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашняя работа:</b>\n",
    "1. Проведите несколько экспериментов с данной моделью. Саму модель не надо менять, меняйте параметры оптимизатора, число эпох обучения и размер батча.\n",
    "2. Получите качество лучшей модели на тестовой выборке.\n",
    "3. Визуализируйте веса Внимания лучшей модели.\n",
    "4. Сделайте выводы, в которых в том числе отметьте: сколько эпох потребовалось для обучения, какое финальное качество модели вы получили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
